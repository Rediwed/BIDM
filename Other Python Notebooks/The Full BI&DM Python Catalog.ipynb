{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook file contains examples and explanations for the Business Intelligence & Data Management course in the Information Management Master at Tilburg University.\n",
    "\n",
    "Contents are adapted from Course Labs 4 through 7, and are up-to-date as of 29-03-2021. Any errors are subject to change. Adapted by: Dewi Cadat\n",
    "\n",
    "Note: You should not run just run each cell in the notebook, as it will results in errors. Read and copy cell contents to another notebook file that you're working in. Then adjust variables and values to fit your situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV File\n",
    "Import pandas as pd\n",
    "\n",
    "# Single command reads CSV into Pandas DataFrame\n",
    "df_from_file = pd.read_csv(r'x')\n",
    "# Replace X with Path to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from SQL Database\n",
    "import sqlite3\n",
    "db_connection = sqlite3.connect(r'X')\n",
    "# Replace X with path to Database file\n",
    "\n",
    "# SELECTS all from [TableName], also grabs columns into cols\n",
    "query = db_connection.execute(\"SELECT * From TableName\")\n",
    "cols = [column[0] for column in query.description]\n",
    "\n",
    "# Actually puts query & cols into a dataframe\n",
    "df_from_database = pd.DataFrame.from_records(data = query.fetchall(), columns = cols)\n",
    "\n",
    "# You can close the connection if you're tidy.\n",
    "db_connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieving data from Data frame [DF]\n",
    "DF.head(5) # returns the top 5 row of the data\n",
    "DF.head(X) # returns the top X row of the data\n",
    "DF.sample(X) # returns X random row\n",
    "\n",
    "# retrieving information related to the columns\n",
    "df_database.columns # show all column names\n",
    "df_database['X'] # show values for column X\n",
    "df_database['X'][A:B] # show values of columns X, from row A to B\n",
    "# NOTE: X here is the name of one column, e.g., Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Scatterplot\n",
    "import matplotlib.pyplot as plt\n",
    "DF.plot.scatter(x='Column-X', y='Column-Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bar Chart\n",
    "import matplotlib.pyplot as plt\n",
    "ts = pd.Series(df_database['Mfg_Year'])\n",
    "ts = ts.hist()\n",
    "ts.set_xlabel('year')\n",
    "ts.set_ylabel('count')\n",
    "ts.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and Run Train_Test_Split\n",
    "# It is required that your data is already imported as df_file!\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NOTE: df_file should be the dataset in the form of a Data Frame containing both the features and the labels\n",
    "X = df_file[['INdependent VARIABLES']] # Column names representing independent variable(s)\n",
    "y = df_file['Dependent variable'] # Columns names representing dependent variable\n",
    "\n",
    "# IF the file has a lot of columns, it might be tedious to write them all out.\n",
    "# Use this alternative!\n",
    "X = df.drop('DEPENDENT VARIABLE',axis=1).values\n",
    "y = df['DEPENDENT VARIABLE'].values\n",
    "\n",
    "# Actually run the TTT, with test_size = 0.4 and random_state = 101\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and run the Confusion Matrix\n",
    "# NOTE: The CF requires that you have already trained a model and made prediction into y_pred\n",
    "import sklearn.metrics as pm\n",
    "\n",
    "# A) Print the confusion matrix to the console\n",
    "pm.confusion_matrix(y_test,y_pred)\n",
    "\n",
    "# B) Store confusion matrix values into tn, fp, fn, tp values\n",
    "tn, fp, fn, tp = pm.confusion_matrix(y_test,y_pred).ravel()\n",
    "\n",
    "# B.2) Print CF values to the console\n",
    "print(\"True Negative: \", tn)\n",
    "print(\"False Positive: \", fp)\n",
    "print(\"False Negative: \", fn)\n",
    "print(\"True Positive: \", tp)\n",
    "\n",
    "# You can also visualize the matrix!\n",
    "import seaborn as sn\n",
    "sn.heatmap(pm.confusion_matrix(y_test,y_pred), annot=True, vmin=0, vmax=170, fmt='.2f')\n",
    "# If the matrix looks weird in your particular case, change vmin and vmax.\n",
    "\n",
    "# CF allows accuracy measurements to be calculated manually!\n",
    "# Importing Confusion Matrix is Required!\n",
    "\n",
    "# First, run the Confusion matrix you have the required values in the correct variables.\n",
    "tn, fp, fn, tp = pm.confusion_matrix(y_test,y_pred).ravel()\n",
    "\n",
    "# Calculate Accuracy\n",
    "man_accuracy = (tn+tp)/(tn+tp+fn+fp)\n",
    "print(\"Accuracy: \",man_accuracy)\n",
    "\n",
    "# Calculate Recall\n",
    "man_recall = tp/(tp+fn)\n",
    "print(\"Recall: \",man_recall)\n",
    "\n",
    "# Calculate Precision\n",
    "man_precision = tp/(tp+fp)\n",
    "print(\"Precision: \",man_precision)\n",
    "\n",
    "# Calculate F1-Measure, precision and recall variables are required!\n",
    "man_f_measure = (2*man_recall*man_precision)/(man_recall+man_precision)\n",
    "print(\"F1-Measure: \",man_f_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize data scaling to prevent skewed results!\n",
    "# For example when the variables are recorded on a different level (meter versus kilometer)\n",
    "\n",
    "# Normalize data scaling\n",
    "from sklearn.preprocessing import normalize\n",
    "df_col = df_diabetes.columns\n",
    "DF = normalize(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a LINEAIR REGRESSION\n",
    "# Train_Test_Split is required!\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Initiate linear Regression model\n",
    "LR_model = LinearRegression()\n",
    "\n",
    "# Train Linear Regression model with X_train and y_train\n",
    "LR_model.fit(X_train, y_train)\n",
    "\n",
    "# Run the Trained LR model to predict values for X_test\n",
    "y_pred = LR_model.predict(X_test)\n",
    "\n",
    "# Some details about the LR Model\n",
    "print('Coefficient of determination:', LR_model.score(X_train,y_train)) # ùëÖ¬≤\n",
    "print('Intercept:', LR_model.intercept_)\n",
    "print('Slope:', LR_model.coef_)\n",
    "\n",
    "# Plot data points and regression line on a diagram\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X_train, y_train, color='g') # This will plot the individual datapoints (X_train & y_train) in Green\n",
    "plt.plot(X_train, LR_model.predict(X_train), color='k') # This will plot the regression line (model_lr) in Black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a GAUSSIAN NAIVE BAYES\n",
    "# Train_Test_Split is required!\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Initiate the GNB model\n",
    "GNB_model = GaussianNB()\n",
    "\n",
    "# Train GND model with X_train and y_train\n",
    "GNB_model.fit(x_train, y_train)\n",
    "\n",
    "# Run the trained GNB model to predict values for X_test\n",
    "y_pred = GNB_model.predict(x_test)\n",
    "\n",
    "# Generate accuracy measurements for the GNB model\n",
    "# First, import the following:\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import score\n",
    "\n",
    "# Now get the accuracy measurements (Precision Score, Recall Value and F1 Score)\n",
    "print(\"Performance measures over testing data set:\")\n",
    "print(\" 0 precision is\", pm.precision_score(y_test,y_pred))\n",
    "print(\" 0 recall is\", pm.recall_score(y_test,y_pred))\n",
    "print(\" 0 f-measure is\", pm.f1_score(y_test,y_pred))\n",
    "\n",
    "# NOTE! You can calculate ROC Curves for GNB (among others)\n",
    "# This will be explained later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a K NEAREST NEIGHBORs\n",
    "# Train_test_split is required!\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initiate the KNN model, replace K with how many neighbors you want!\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=K)\n",
    "\n",
    "# Train KNN model with X_train and y_train\n",
    "KNN_model.fit(X_train,y_train)\n",
    "\n",
    "# Run the trained GNB model to predict values for X_test\n",
    "y_pred = KNN_model.predict(X_test)\n",
    "\n",
    "# Get Accuracy Measurements over your KNN Model\n",
    "# Import Performance Measures from SKLearn\n",
    "import sklearn.metrics as pm\n",
    "\n",
    "# Print measures to the console!\n",
    "print(\"Performance measures over testing data set:\")\n",
    "print(\" o accuracy is \", pm.accuracy_score(y_test,y_pred))\n",
    "\n",
    "# NOTE: SKLearn Performance Measures assume your predictions are labeled either 0 or 1 by default.\n",
    "# IF your predictions are structured in another way, (e.g. M and B instead of 1 and 0) use the 'pos_label=' argument.\n",
    "# In the exaple below, an 'M' is a positive outcome.\n",
    "print(\" o precision is \", pm.precision_score(y_test, y_pred, pos_label='M'))\n",
    "print(\" o recall is \", pm.recall_score(y_test, y_pred, pos_label='M'))\n",
    "print(\" o f-measure is\", pm.f1_score(y_test, y_pred, pos_label='M'))\n",
    "\n",
    "# I'll explain how to plot the ROC in another field (below)\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# To plot the ROC, you don't work with the predictions, but with class probability scores (predict_proba)\n",
    "y_scores = knn_model.predict_proba(X_test)\n",
    "\n",
    "# Then, you define the true ans false positive rates\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "\n",
    "# You might want the Area Under Curve (AUC) also! \n",
    "from sklearn.metrics import auc\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(roc_auc)\n",
    "\n",
    "# Now to plot the ROC\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr) # This plots the ROC values from your model\n",
    "plt.plot([0,1],[0,1],'r--') # This plots the dotted red curve that is your 'random' performance baselien\n",
    "plt.xlim([0,1]) # This defines the x range of the diagram\n",
    "plt.ylim([0,1]) # This defines the y range of the diagram\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Corve of kNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run a DECISION TREE\n",
    "\n",
    "# Warning: To run this tree you need to install a whole bunch of extra modules.\n",
    "# You'll have to figure out how to do this yourself.\n",
    "\n",
    "\n",
    "# Train_Test_Split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Optional! Replace categorical values with dummy variable\n",
    "import pandas as pd\n",
    "X = pd.get_dummies(DF[predictors]) # 'predictors' should be a variable with the column name. Or you can write the column names directly.\n",
    "y = DF['DEPENDENT Variables'].values\n",
    "\n",
    "# Initiate the Decision Tree\n",
    "fullClassTree = DecisionTreeClassifier()\n",
    "\n",
    "# Train Decision Tree with X_train and y_train\n",
    "fullClassTree.fit(X_train,y_train)\n",
    "\n",
    "# Before predicting values using the tree, you can already plot the current model\n",
    "from dmba import plotDecisionTree\n",
    "plotDecisionTree(fullClassTree,feature_names=X_train.columns, class_names=fullClassTree.classes_)\n",
    "\n",
    "# Predict y values (y_pred) using the fullClassTree!\n",
    "y_pred = fullClassTree.predict(X_test)\n",
    "\n",
    "# E.g. this lets you calculate the tree's precision score\n",
    "import sklearn.metrics as pm\n",
    "pm.precision_score(y_test, y_pred)\n",
    "\n",
    "# In the lab it is not explained how you plot the tree including X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC CURVES (& calculate AUC VALUES)\n",
    "\n",
    "# For GaussianND, Multinomial NB and KNeighborsClassifier!\n",
    "\n",
    "# First, initiate and train EACH model (see explanations above).\n",
    "# Don't forget Train_Test_Split :)\n",
    "\n",
    "# Then, initiate the modules to calculate class probability values for each model\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "import sklearn.metrics\n",
    "\n",
    "# Calculate class probility for KNeighbordsClassifier\n",
    "y_pred_proba_KNN = KNN_Model.predict_proba(X_test)[:,1]\n",
    "avg_prec_score_KNN = sklearn.metrics.average_precision_score(y_test, y_pred_proba_KNN)\n",
    "\n",
    "# For MultinomialNB\n",
    "y_pred_proba_MNB = MNB_Model.predict_proba(X_test)[:,1]\n",
    "avg_prec_score_MNB = sklearn.metrics.average_precision_score(y_test, y_pred_proba_MNB)\n",
    "\n",
    "# For GaussianNB\n",
    "y_pred_proba_model_GaussianNB = model_GaussianNB.predict_proba(X_test)[:,1]\n",
    "avg_prec_score_GNB = sklearn.metrics.average_precision_score(y_test, y_pred_proba_model_GaussianNB)\n",
    "\n",
    "# (Optional) Now, you can print average precision scores \n",
    "print('Average precision score KNN: ', avg_prec_score_KNN)\n",
    "print('Average precision score MNB: ', avg_prec_score_MNB)\n",
    "print('Average precision score GNB: ', avg_prec_score_GNB)\n",
    "\n",
    "# Define ROC Curve values for each model\n",
    "fpr_GNB, tpr_GNB, thresholds_GaussianNB = roc_curve(y_test, y_pred_proba_model_GaussianNB)\n",
    "fpr_MNB, tpr_MNB, thresholds_MNB = roc_curve(y_test, y_pred_proba_MNB)\n",
    "fpr_KNN,tpr_KNN, thresholds_KNN = roc_curve(y_test, y_pred_proba_KNN)\n",
    "\n",
    "# Define area under curce (ROC curve values, above, needed)\n",
    "GNB_auc = auc(fpr_GNB, tpr_GNB)\n",
    "MNB_auc = auc(fpr_MNB, tpr_MNB)\n",
    "KNN_auc = auc(fpr_KNN, tpr_KNN)\n",
    "\n",
    "# Print AUC values per model\n",
    "print('Gaussian NB: ',GNB_auc)\n",
    "print('Multinomial NB: ',MNB_auc)\n",
    "print('KNeighbors: ',KNN_auc)\n",
    "\n",
    "# Plot ROC Curves\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr_GNB, tpr_GNB, label='GNB') # Plots the GNB curve\n",
    "plt.plot(fpr_KNN, tpr_KNN, label='KNN') # Plots the KBB curve\n",
    "plt.plot(fpr_MNB, tpr_MNB, label='MNB') # Plots the MNB curve\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlabel('false positive ratio')\n",
    "plt.ylabel('true positive ratio')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DENDROGRAM (hierarchical clustering)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as shc\n",
    "\n",
    "# Remember to normalize data scaling!\n",
    "\n",
    "# convert ndarray to pd\n",
    "DF = pd.DataFrame(DF, columns = df_col)\n",
    "\n",
    "# Actually make the Dendrogram\n",
    "plt.figure(figsize=(10, 7)) # Adjust these values to adjust figure size\n",
    "plt.title(\"Dendrograms\")\n",
    "dend = shc.dendrogram(shc.linkage(DF, method='ward'))\n",
    "\n",
    "# Visualise hierarchical clusters\n",
    "plt.figure(figsize=(10, 7)) # Adjust these values to adjust figure size\n",
    "plt.scatter(DF['VAR1'], DF['VAR2'], c=cluster.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ASSOCIATION RULES\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Transform DataFrame into list of lists\n",
    "transactions = []\n",
    "for i in range(len(data)):\n",
    "    row=[]\n",
    "    for j in range(len(data.columns)):\n",
    "        if str(data.values[i,j])!='nan':\n",
    "            row.append(str(data.values[i,j]))\n",
    "    transactions.append(row)\n",
    "    \n",
    "# Initate the Association Rule module\n",
    "te = TransactionEncoder()\n",
    "\n",
    "# Fit the module on the data.\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "# NOTE: In this case the variable is transaction. It has to be a list of lists.\n",
    "\n",
    "# Retrieve the frequent itemsets with support higher than 0.05\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_) # Not sure what this does\n",
    "frequent_itemsets = apriori(df, min_support=0.05, use_colnames=True)\n",
    "\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Create Association Rules with confidence being at 35% or higher\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.05)\n",
    "print(rules)\n",
    "\n",
    "# Alternatively, you can limit rules by their lift value\n",
    "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
    "print(rules)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CLUSTERS (K-Means)\n",
    "from sklearn.metrics import pairwise\n",
    "\n",
    "# Create itempairs using euclidian distance \n",
    "d = pairwise.pairwise_distances(wine_df, metric='euclidean') # Use Manhatten in case of outliers\n",
    "\n",
    "# Determine amount of cells in itemspairs\n",
    "d.size\n",
    "\n",
    "# Now we'll run the K-Means model at different values for K to see which is best.\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlyb.pyplot as plt\n",
    "\n",
    "Error =[]\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters = i)\n",
    "    kmeans.fit(wine_df)\n",
    "    Error.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 11), Error)\n",
    "plt.xlabel('No of clusters')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
